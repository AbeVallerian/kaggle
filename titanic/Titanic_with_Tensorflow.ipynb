{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54a3948b-713d-4a07-9ba6-ac718c06a132",
    "_uuid": "304d862d352d8ead504f586ce8210c130a35602f"
   },
   "source": [
    "# Logistic Regression with Tensorflow\n",
    "\n",
    "I know it is quite overkill to use Tensorflow for this task, but I just learned using Tensorflow and I want to apply what I've learned in this task. Basically, I'm going to build Logistic Regression using Tensorflow. So, let's begin!\n",
    "\n",
    "First, I start importing the libraries and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1cfbe74d-4e3a-4f90-8f60-ffa71f32d8fa",
    "_uuid": "d477307493c72c7655bdb0fff66ace25fe355a94",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3057de14-8cf2-4893-9314-80dba16984ce",
    "_uuid": "2df18247179fb7ef4e8742d04fa4807c5ffd8a2f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34b2700e-4ee4-4a26-b5a7-add24f566635",
    "_uuid": "276c2b5d79cc5f941e70be9978f5866b1c21926d"
   },
   "source": [
    "## Preprocessing the Data\n",
    "Let's just take a quick view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "23fc8036-3ce3-4ac7-a429-07485d05471f",
    "_uuid": "cf7c94315f3922587035f20cbc8329ae9053b65e",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "f6fccb06-8451-4d26-b0be-90562ca14693",
    "_uuid": "959e5403851711e14b7c99ff41b9c900d31c2f73",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "72b78491-a105-41d9-a43c-b6e317ff4295",
    "_uuid": "4f9eb7022143c110b7bd0e52603ad06094974c8c",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c24ece66-2214-4c4e-8f09-981b918cf898",
    "_uuid": "ba7464fe14bcef110c4afce8877ff56be2dbe6c8",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a10b0e4-c5c2-4791-91c9-b6de78a77c9a",
    "_uuid": "de8258e33b507a4756ef45ee716872b601bfec45"
   },
   "source": [
    "The goal of this project is to predict whether a passenger survives. Therefore, I don't think that *Name*, *Ticket*, *Fare*, and *Embarkment* are related to survival. Just delete those columns from the table. Moreover, there are also several *NaN* in the table. Replace those *NaN*s with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "49096527-4af1-46ce-a9fe-5492715205e0",
    "_uuid": "77cd356fe0c660bbe7407b4f6df2b1e02a6d5d7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['Name']\n",
    "del train['Ticket']\n",
    "del train['Fare']\n",
    "del train['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8d8f6b88-68e1-45db-9753-cb36932a2ffb",
    "_uuid": "bec8739154048a12886275e79718cb0bb4b0dd9c",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0da2fb10-53d8-4ab2-8c24-5d3bfd6eb6f9",
    "_uuid": "65746702bc6c3760a577f1bc7278a620439fa613"
   },
   "source": [
    "1. First, let's preprocess the *Sex*. Just replace it with 0 (Female) or 1 (Male).\n",
    "2. Then, let's handle the *Age*. Since the age is categorical data, I group the age 8 groups: *NaN*, 0-10, 10-20, ..., 70-80. From the desribe above, it's shown that the maximum age is 80.\n",
    "3. *Cabin* is quite interesting. It is stored in string. I think the format is written as *Cabin Section + Cabin Number*. I'm only interested in obtaining the *Cabin Section*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "12478a25-42a6-470b-938c-957af41052de",
    "_uuid": "0272d2e7b8042932288ab27d1a447a1cb27bafe4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]):\n",
    "    if train.at[i, 'Sex'] == 'male':\n",
    "        train.at[i, 'Sex'] = 1\n",
    "    else:\n",
    "        train.at[i, 'Sex'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "f912af27-ab75-40c8-91d4-d69ec126157c",
    "_uuid": "e8851ca16628e4a38d6871c4d1517b9d31fffbd2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Age_group'] = 0\n",
    "for i in range(train.shape[0]):\n",
    "    for j in range(70, 0, -10):\n",
    "        if train.at[i, 'Age'] > j:\n",
    "            train.at[i, 'Age_group'] = int(j/10)\n",
    "            break\n",
    "del train['Age'] # it's unnecessary anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "c202285e-f184-471d-9783-8cd79c484ee2",
    "_uuid": "dc0e27980e29ab6f9b362b091a6d03cd0f470e38",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 'C99', 'E68', 'C54', 'E49', 'D10 D12', 'D35', 'B3', 'C87', 'C93']\n",
      "['B', 'C', '0', 'A', 'D', 'E', 'T', 'F', 'G']\n"
     ]
    }
   ],
   "source": [
    "print(list(set(train['Cabin'].values))[:10]) # sample of 'Cabin' values\n",
    "train['Cabin_section'] = '0'\n",
    "for i in range(train.shape[0]):\n",
    "    if train.at[i, 'Cabin'] != 0:\n",
    "        train.at[i, 'Cabin_section'] = train.at[i, 'Cabin'][0]\n",
    "CABIN_SECTION = list(set(train['Cabin_section'].values)) # will be reused for test data\n",
    "print(CABIN_SECTION) # 'Cabin_Section' values\n",
    "for i in range(train.shape[0]):\n",
    "    train.at[i, 'Cabin_section'] = CABIN_SECTION.index(train.at[i, 'Cabin_section'])\n",
    "del train['Cabin'] # it's unnecessary anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13ba756d-db72-43cb-9a95-e5c48258b250",
    "_uuid": "de567fb6a6985f2d093a3e6355112d102869492d"
   },
   "source": [
    "I've done with the preprocessing. Here is the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "aa0825ff-6691-409e-9bbf-a5802cf88bb0",
    "_uuid": "3ebd8d1b2fdafcf9edbceedd2e914ce2e33b6e50",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_group</th>\n",
       "      <th>Cabin_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass Sex  SibSp  Parch  Age_group Cabin_section\n",
       "0            1         0       3   1      1      0          2             2\n",
       "1            2         1       1   0      1      0          3             1\n",
       "2            3         1       3   0      0      0          2             2\n",
       "3            4         1       1   0      1      0          3             1\n",
       "4            5         0       3   1      0      0          3             2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c6de35c9-52ba-4817-adba-b6455f7aeb70",
    "_uuid": "7e7e405dd8535e35862b8f505c0bd3ef4485e7c9"
   },
   "source": [
    "What's next is preparing the numpy array for the input of Tensorflow. I need to convert the categorical data (*Pclass*, *Age_group*, and *Cabin_section*) into *one hot* array using np.eye. Then, divide the data into training and dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "1efe0a95-2f2e-4706-bc02-ab8d39817878",
    "_uuid": "19be0a2fa6cc9bfdd3f31d13ee98183c86f0f10c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass = np.eye(train['Pclass'].values.max()+1)[train['Pclass'].values]\n",
    "age_group = np.eye(train['Age_group'].values.max()+1)[train['Age_group'].values]\n",
    "cabin_section = np.eye(train['Cabin_section'].values.max()+1) \\\n",
    "                    [train['Cabin_section'].values.astype(int)] # prevent IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "deccf367-69fc-4048-be97-2c71d3188d09",
    "_uuid": "1908ef641d0038dff9a273e9053c3fc8235b5ffb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[['Sex', 'SibSp', 'Parch']].values\n",
    "X = np.concatenate([X, age_group], axis=1)\n",
    "X = np.concatenate([X, pclass], axis=1)\n",
    "X = np.concatenate([X, cabin_section], axis=1)\n",
    "X = X.astype(float)\n",
    "\n",
    "y = train['Survived'].values\n",
    "y = y.astype(float).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "291a631f-bb72-4cf6-8fac-58e1a01c8881",
    "_uuid": "9e930094d7790d619bf443186b7fc99b0745f4f4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b2ca280c-ef22-463d-9c01-20f459db9b44",
    "_uuid": "087d8d30992f7634c060de39b237272f8582a2c4",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 24) (801, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cbb219f9-5078-421e-a561-396948e0351a",
    "_uuid": "16c960e2a1c09efb722d2e2a39cb0b3768aa798e"
   },
   "source": [
    "Repeat the preprocessing for the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "4f9cf1d5-cf23-4898-8942-07eb2f6277fe",
    "_uuid": "baebb61f7665a6e19e5f922448339285d2fa98a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del test['Name']\n",
    "del test['Ticket']\n",
    "del test['Fare']\n",
    "del test['Embarked']\n",
    "\n",
    "test = test.fillna(value=0.0)\n",
    "\n",
    "test['Age_group'] = 0\n",
    "test['Cabin_section'] = '0'\n",
    "for i in range(test.shape[0]):\n",
    "    if test.at[i, 'Sex'] == 'male':\n",
    "        test.at[i, 'Sex'] = 1\n",
    "    else:\n",
    "        test.at[i, 'Sex'] = 0\n",
    "\n",
    "    for j in range(70, 0, -10):\n",
    "        if test.at[i, 'Age'] > j:\n",
    "            test.at[i, 'Age_group'] = int(j/10)\n",
    "            break\n",
    "\n",
    "    if test.at[i, 'Cabin'] != 0:\n",
    "        test.at[i, 'Cabin_section'] = test.at[i, 'Cabin'][0]\n",
    "    test.at[i, 'Cabin_section'] = CABIN_SECTION.index(test.at[i, 'Cabin_section'])\n",
    "\n",
    "del test['Cabin'] # it's unnecessary anymore\n",
    "del test['Age'] # it's unnecessary anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "c60b7624-41a3-4cc0-bac4-7c96da57c4a1",
    "_uuid": "182bbfc7540b9e2f04f6f2739f321097676313d2",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_group</th>\n",
       "      <th>Cabin_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass Sex  SibSp  Parch  Age_group Cabin_section\n",
       "0          892       3   1      0      0          3             2\n",
       "1          893       3   0      1      0          4             2\n",
       "2          894       2   1      0      0          6             2\n",
       "3          895       3   1      0      0          2             2\n",
       "4          896       3   0      1      1          2             2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "31deadf3-1b9b-4dd3-ac74-aa9af894424a",
    "_uuid": "f4bba6a4daeba396a21b89ca7b0b278c78ba828b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_test = np.eye(test['Pclass'].values.max()+1)[test['Pclass'].values]\n",
    "age_group_test = np.eye(test['Age_group'].values.max()+1)[test['Age_group'].values]\n",
    "cabin_section_test = np.eye(test['Cabin_section'].values.max()+1) \\\n",
    "                    [test['Cabin_section'].values.astype(int)] # prevent IndexError\n",
    "\n",
    "X_test = test[['Sex', 'SibSp', 'Parch']].values\n",
    "X_test = np.concatenate([X_test, age_group_test], axis=1)\n",
    "X_test = np.concatenate([X_test, pclass_test], axis=1)\n",
    "X_test = np.concatenate([X_test, cabin_section_test], axis=1)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "id_test = test['PassengerId'].values\n",
    "id_test = id_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "bfa30d78-d3e3-4f73-922a-0ac4d9a8d03f",
    "_uuid": "d11b1333617d3aed45149173717ee38f33e50ad7",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 24) (418, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, id_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1947257e-cc0d-4c27-9b13-7076ee081d52",
    "_uuid": "89d27c6d5b4109fb5e7170760dfdb1fa9f150a27"
   },
   "source": [
    "## Building the Neural Network\n",
    "Let's start by defining the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "9baac1a4-9bf5-40c4-be17-ba8b1b02570c",
    "_uuid": "5e82f7ba1a23be1501d33dad6b462a904d608709",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7 # for reproducible purpose\n",
    "input_size = X_train.shape[1] # number of features\n",
    "learning_rate = 0.001 # most common value for Adam\n",
    "epochs = 8500 # I've tested previously that this is the best epochs to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "44b85950-8dc4-42eb-905e-2d19dab3686d",
    "_uuid": "1d1359e39b68cc470076b1aaa0352fa20add31b1"
   },
   "source": [
    "The Logistic Regression looks like this: W1\\*X + b1 = pred, where \\* is the matrix multiplication and sigmoid is used as activation function at the output layer. *Cross Entropy* and *Adam Optimizer* are used as the loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "ceea2310-e4d4-48d3-b1e1-04fd8d6389cc",
    "_uuid": "ba18a2b4bfc98cb1978876895a88a049b060a6d1",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    X_input = tf.placeholder(dtype=tf.float32, shape=[None, input_size], name='X_input')\n",
    "    y_input = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='y_input')\n",
    "    \n",
    "    W1 = tf.Variable(tf.random_normal(shape=[input_size, 1], seed=seed), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[1], seed=seed), name='b1')\n",
    "    sigm = tf.nn.sigmoid(tf.add(tf.matmul(X_input, W1), b1), name='pred')\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_input,\n",
    "                                                                  logits=sigm, name='loss'))\n",
    "    train_steps = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    pred = tf.cast(tf.greater_equal(sigm, 0.5), tf.float32, name='pred') # 1 if >= 0.5\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(pred, y_input), tf.float32), name='acc')\n",
    "    \n",
    "    init_var = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "878191e3-5d61-46dd-bc04-cf301e05475d",
    "_uuid": "a12f3e95eb67c34abc237f7d072f2bccc4af3f43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed_dict = {X_input: X_train, y_input: y_train}\n",
    "dev_feed_dict = {X_input: X_dev, y_input: y_dev}\n",
    "test_feed_dict = {X_input: X_test} # no y_input since the goal is to predict it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13ccf448-b160-48aa-bb95-5cad170f0d7c",
    "_uuid": "138a11e1d0f4d4bdee48c20cf63ba37675919b37"
   },
   "source": [
    "## Training the Network\n",
    "Let's start the training. I initialize the session and variables first and start the training. During training, the loss and accuracy are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "830a610d-65a1-49c3-b567-37066beeff9d",
    "_uuid": "5aa9f28ab236a2553d24c5baf540bf452416d7f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "52bb4657-3d99-4d2c-9b13-650a7953097b",
    "_uuid": "88eec1b222eba807e0975ceaee55b268d6fc9043",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss 0.72769, train_acc 65.17%, test_acc 67.78%\n",
      "step 100: loss 0.71315, train_acc 65.04%, test_acc 60.00%\n",
      "step 200: loss 0.70363, train_acc 64.17%, test_acc 58.89%\n",
      "step 300: loss 0.69718, train_acc 63.80%, test_acc 61.11%\n",
      "step 400: loss 0.69236, train_acc 64.42%, test_acc 62.22%\n",
      "step 500: loss 0.68835, train_acc 65.04%, test_acc 63.33%\n",
      "step 600: loss 0.68477, train_acc 66.04%, test_acc 67.78%\n",
      "step 700: loss 0.68153, train_acc 67.42%, test_acc 68.89%\n",
      "step 800: loss 0.67860, train_acc 68.79%, test_acc 70.00%\n",
      "step 900: loss 0.67600, train_acc 69.79%, test_acc 70.00%\n",
      "step 1000: loss 0.67370, train_acc 70.41%, test_acc 71.11%\n",
      "step 1100: loss 0.67168, train_acc 70.79%, test_acc 71.11%\n",
      "step 1200: loss 0.66988, train_acc 71.91%, test_acc 72.22%\n",
      "step 1300: loss 0.66826, train_acc 72.16%, test_acc 74.44%\n",
      "step 1400: loss 0.66677, train_acc 72.41%, test_acc 75.56%\n",
      "step 1500: loss 0.66539, train_acc 73.41%, test_acc 75.56%\n",
      "step 1600: loss 0.66411, train_acc 74.28%, test_acc 75.56%\n",
      "step 1700: loss 0.66291, train_acc 74.66%, test_acc 75.56%\n",
      "step 1800: loss 0.66178, train_acc 74.78%, test_acc 75.56%\n",
      "step 1900: loss 0.66071, train_acc 75.41%, test_acc 76.67%\n",
      "step 2000: loss 0.65970, train_acc 75.66%, test_acc 77.78%\n",
      "step 2100: loss 0.65872, train_acc 76.15%, test_acc 75.56%\n",
      "step 2200: loss 0.65780, train_acc 76.40%, test_acc 75.56%\n",
      "step 2300: loss 0.65690, train_acc 76.40%, test_acc 75.56%\n",
      "step 2400: loss 0.65605, train_acc 76.53%, test_acc 75.56%\n",
      "step 2500: loss 0.65522, train_acc 77.15%, test_acc 75.56%\n",
      "step 2600: loss 0.65442, train_acc 78.03%, test_acc 75.56%\n",
      "step 2700: loss 0.65365, train_acc 78.40%, test_acc 75.56%\n",
      "step 2800: loss 0.65290, train_acc 78.28%, test_acc 76.67%\n",
      "step 2900: loss 0.65218, train_acc 78.28%, test_acc 76.67%\n",
      "step 3000: loss 0.65147, train_acc 78.28%, test_acc 75.56%\n",
      "step 3100: loss 0.65080, train_acc 78.28%, test_acc 75.56%\n",
      "step 3200: loss 0.65014, train_acc 78.15%, test_acc 75.56%\n",
      "step 3300: loss 0.64950, train_acc 78.53%, test_acc 76.67%\n",
      "step 3400: loss 0.64889, train_acc 78.90%, test_acc 76.67%\n",
      "step 3500: loss 0.64829, train_acc 79.03%, test_acc 76.67%\n",
      "step 3600: loss 0.64771, train_acc 79.15%, test_acc 76.67%\n",
      "step 3700: loss 0.64715, train_acc 79.15%, test_acc 76.67%\n",
      "step 3800: loss 0.64661, train_acc 79.15%, test_acc 76.67%\n",
      "step 3900: loss 0.64609, train_acc 79.15%, test_acc 76.67%\n",
      "step 4000: loss 0.64559, train_acc 79.03%, test_acc 76.67%\n",
      "step 4100: loss 0.64510, train_acc 79.28%, test_acc 76.67%\n",
      "step 4200: loss 0.64463, train_acc 79.28%, test_acc 76.67%\n",
      "step 4300: loss 0.64418, train_acc 79.65%, test_acc 77.78%\n",
      "step 4400: loss 0.64374, train_acc 79.65%, test_acc 77.78%\n",
      "step 4500: loss 0.64332, train_acc 79.65%, test_acc 77.78%\n",
      "step 4600: loss 0.64291, train_acc 79.65%, test_acc 78.89%\n",
      "step 4700: loss 0.64252, train_acc 79.65%, test_acc 78.89%\n",
      "step 4800: loss 0.64213, train_acc 79.65%, test_acc 78.89%\n",
      "step 4900: loss 0.64177, train_acc 79.78%, test_acc 78.89%\n",
      "step 5000: loss 0.64141, train_acc 79.78%, test_acc 78.89%\n",
      "step 5100: loss 0.64107, train_acc 79.78%, test_acc 78.89%\n",
      "step 5200: loss 0.64074, train_acc 79.78%, test_acc 78.89%\n",
      "step 5300: loss 0.64041, train_acc 79.78%, test_acc 78.89%\n",
      "step 5400: loss 0.64010, train_acc 79.78%, test_acc 78.89%\n",
      "step 5500: loss 0.63980, train_acc 79.78%, test_acc 78.89%\n",
      "step 5600: loss 0.63951, train_acc 79.78%, test_acc 78.89%\n",
      "step 5700: loss 0.63923, train_acc 79.78%, test_acc 78.89%\n",
      "step 5800: loss 0.63896, train_acc 79.78%, test_acc 78.89%\n",
      "step 5900: loss 0.63870, train_acc 79.78%, test_acc 78.89%\n",
      "step 6000: loss 0.63844, train_acc 79.78%, test_acc 78.89%\n",
      "step 6100: loss 0.63819, train_acc 79.78%, test_acc 78.89%\n",
      "step 6200: loss 0.63795, train_acc 79.78%, test_acc 78.89%\n",
      "step 6300: loss 0.63772, train_acc 79.78%, test_acc 78.89%\n",
      "step 6400: loss 0.63750, train_acc 79.78%, test_acc 78.89%\n",
      "step 6500: loss 0.63728, train_acc 79.78%, test_acc 78.89%\n",
      "step 6600: loss 0.63707, train_acc 79.78%, test_acc 78.89%\n",
      "step 6700: loss 0.63686, train_acc 79.78%, test_acc 78.89%\n",
      "step 6800: loss 0.63666, train_acc 79.65%, test_acc 78.89%\n",
      "step 6900: loss 0.63647, train_acc 79.65%, test_acc 78.89%\n",
      "step 7000: loss 0.63628, train_acc 79.65%, test_acc 78.89%\n",
      "step 7100: loss 0.63610, train_acc 79.65%, test_acc 78.89%\n",
      "step 7200: loss 0.63593, train_acc 79.65%, test_acc 78.89%\n",
      "step 7300: loss 0.63575, train_acc 79.65%, test_acc 78.89%\n",
      "step 7400: loss 0.63559, train_acc 79.65%, test_acc 78.89%\n",
      "step 7500: loss 0.63543, train_acc 79.65%, test_acc 78.89%\n",
      "step 7600: loss 0.63527, train_acc 79.65%, test_acc 78.89%\n",
      "step 7700: loss 0.63512, train_acc 79.65%, test_acc 78.89%\n",
      "step 7800: loss 0.63497, train_acc 79.65%, test_acc 78.89%\n",
      "step 7900: loss 0.63482, train_acc 79.65%, test_acc 78.89%\n",
      "step 8000: loss 0.63468, train_acc 79.65%, test_acc 78.89%\n",
      "step 8100: loss 0.63454, train_acc 79.65%, test_acc 78.89%\n",
      "step 8200: loss 0.63440, train_acc 79.65%, test_acc 78.89%\n",
      "step 8300: loss 0.63427, train_acc 79.65%, test_acc 78.89%\n",
      "step 8400: loss 0.63412, train_acc 79.65%, test_acc 78.89%\n",
      "step 8500: loss 0.63394, train_acc 79.65%, test_acc 78.89%\n"
     ]
    }
   ],
   "source": [
    "cur_loss = sess.run(loss, feed_dict=train_feed_dict)\n",
    "train_acc = sess.run(acc, feed_dict=train_feed_dict)\n",
    "test_acc = sess.run(acc, feed_dict=dev_feed_dict)\n",
    "print('step 0: loss {0:.5f}, train_acc {1:.2f}%, test_acc {2:.2f}%'.format(\n",
    "                       cur_loss, 100*train_acc, 100*test_acc))\n",
    "for step in range(1, epochs+1):\n",
    "    sess.run(train_steps, feed_dict=train_feed_dict)\n",
    "    cur_loss = sess.run(loss, feed_dict=train_feed_dict)\n",
    "    train_acc = sess.run(acc, feed_dict=train_feed_dict)\n",
    "    test_acc = sess.run(acc, feed_dict=dev_feed_dict)\n",
    "    if step%100 != 0: # print result every 100 steps\n",
    "        continue\n",
    "    print('step {3}: loss {0:.5f}, train_acc {1:.2f}%, test_acc {2:.2f}%'.format(\n",
    "                       cur_loss, 100*train_acc, 100*test_acc, step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f90ec9e2-dfda-4662-a01a-770d57b3fa18",
    "_uuid": "c8adc7882329ccd6d43ec1507effcc8ee363c28b"
   },
   "source": [
    "## Evaluating the Network\n",
    "Actually the network performance is not very good (only around 80%). Finally, I need to prepare the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "1814d9ca-894f-4bdb-a5f4-bef94bd260ef",
    "_uuid": "19a93c8ba9198c49fbfa19e652c24ba359a5d517",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = sess.run(pred, feed_dict=test_feed_dict).astype(int)\n",
    "prediction = pd.DataFrame(np.concatenate([id_test, y_pred], axis=1),\n",
    "                          columns=['PassengerId', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "139859b0-017a-49bf-9640-4b7d7b8a6d8e",
    "_uuid": "0673bdfe031f40ac969b065f2cf765f43fa4a882",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8839a202-8b9f-4282-b5c7-5eb127adc061",
    "_uuid": "877c1c7a2eb90fa5d8b7292807fc10fe7a152157"
   },
   "source": [
    "## Takeaways\n",
    "1. I think I'm not doing enough Exploratory Data Analysis, which I think very crucial in beginning the project.\n",
    "2.  80% accuracy in train and dev set is not very good actually. I think other models such as Random Forest will produce better accuracy.\n",
    "3. Even if Logistic Regression should be used, using Tensorflow is not very efficient. There are many build-in libraries for Logistic Regression (e.g. Scikit-Learn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a95e5ec0-ac6a-4a38-9edd-88064d59d8cc",
    "_uuid": "6578fdcce4e3c968f29036fc3fc59ff7f53b2bba",
    "collapsed": true
   },
   "source": [
    "Any feedbacks are very welcomed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
